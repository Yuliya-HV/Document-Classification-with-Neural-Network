{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#!pip install -q tensorflow-gpu==2.0.0-beta1\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge labeled 0 and 1 data and add documents as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = pd.concat([df_label_1, df_label_00], axis = 0)\n",
    "df_labeled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>advocate industry enterprise journal mechanica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>steam ship great britain vavt lif pzwexoe irl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>speak gently peak gently better far rule love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>valuable recent publications harper brothers b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>advocate industry enterprise journal mechanica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             output\n",
       "0   0  advocate industry enterprise journal mechanica...\n",
       "1   1  steam ship great britain vavt lif pzwexoe irl ...\n",
       "2   2  speak gently peak gently better far rule love ...\n",
       "3   3  valuable recent publications harper brothers b...\n",
       "4   4  advocate industry enterprise journal mechanica..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docs = pd.read_csv('docs.csv', names = [\"ID\", 'output'])\n",
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>phrases</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62757</td>\n",
       "      <td>1</td>\n",
       "      <td>['direct_current', 'alternating_current', 'dir...</td>\n",
       "      <td>direct current era return discussing general q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40648</td>\n",
       "      <td>1</td>\n",
       "      <td>['induction_motors', 'induction_motors', 'sing...</td>\n",
       "      <td>electric traction long distance railways ton a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label                                            phrases  \\\n",
       "0  62757      1  ['direct_current', 'alternating_current', 'dir...   \n",
       "1  40648      1  ['induction_motors', 'induction_motors', 'sing...   \n",
       "\n",
       "                                              output  \n",
       "0  direct current era return discussing general q...  \n",
       "1  electric traction long distance railways ton a...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total = pd.merge(df_labeled, df_docs, on = 'ID')\n",
    "df_total.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12264 entries, 0 to 12263\n",
      "Data columns (total 4 columns):\n",
      "ID         12264 non-null int64\n",
      "label      12264 non-null int64\n",
      "phrases    6132 non-null object\n",
      "output     12232 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 479.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_total.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "train, test = train_test_split(df_total, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "      <th>phrases</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>115888</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tion interested geometers whether independent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>41850</td>\n",
       "      <td>1</td>\n",
       "      <td>['electric_machine', 'manufactur_ing', 'electr...</td>\n",
       "      <td>curtain roll support jones fin tain shade adju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>150754</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>horizontal linear polarization left irciji pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683</th>\n",
       "      <td>152991</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>begin voyage discovery takes quarks cosmos bey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>167951</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reviews sight mind oncoming crisis misuse hidd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  label                                            phrases  \\\n",
       "9680   115888      0                                                NaN   \n",
       "3983    41850      1  ['electric_machine', 'manufactur_ing', 'electr...   \n",
       "10007  150754      0                                                NaN   \n",
       "8683   152991      0                                                NaN   \n",
       "11379  167951      0                                                NaN   \n",
       "\n",
       "                                                  output  \n",
       "9680   tion interested geometers whether independent ...  \n",
       "3983   curtain roll support jones fin tain shade adju...  \n",
       "10007  horizontal linear polarization left irciji pol...  \n",
       "8683   begin voyage discovery takes quarks cosmos bey...  \n",
       "11379  reviews sight mind oncoming crisis misuse hidd...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in train.output:\n",
    "    for word in str(text).split(' '):\n",
    "        vocab[word] += 1\n",
    "for text in test.output:\n",
    "    for word in str(text).split(' '):\n",
    "        vocab[word] += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocabulary: 255177\n"
     ]
    }
   ],
   "source": [
    "print('Total words in vocabulary: {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the word AUTOMATION: 17562\n"
     ]
    }
   ],
   "source": [
    "total_words = len(vocab)\n",
    "\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i, word in enumerate(vocab):\n",
    "        word2index[word] = i\n",
    "    return word2index\n",
    "\n",
    "word2index = get_word_2_index(vocab)\n",
    "\n",
    "print('Index of the word AUTOMATION:', word2index['automation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vector(text):\n",
    "    layer = np.zeros(total_words, dtype = float)\n",
    "    for word in str(text).split(' '):\n",
    "        if word in word2index.keys():\n",
    "            layer[word2index[word]] += 1\n",
    "    return layer\n",
    "\n",
    "def category_to_vector(category):\n",
    "    y = np.zeros((2), dtype = float)\n",
    "    if category == 0:\n",
    "        y[0] = 1.\n",
    "    else:\n",
    "        y[1] = 1.\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch( df, i, batch_size):\n",
    "    batches = []\n",
    "    results = []\n",
    "    texts = df.output[i*batch_size: i*batch_size+batch_size]\n",
    "    categories = df.label[i*batch_size: i*batch_size+batch_size]\n",
    "    \n",
    "    for text in texts:\n",
    "        layer = text_to_vector(text)\n",
    "        batches.append(layer)\n",
    "        \n",
    "    for category in categories:\n",
    "        y = category_to_vector(category)\n",
    "        results.append(y)\n",
    "        \n",
    "    return np.array(batches), np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 255177)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#documents\n",
    "get_batch(train, 1, 100)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels\n",
    "get_batch(train, 1, 100)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 10\n",
    "batch_size = 150\n",
    "display_step = 1\n",
    "\n",
    "#network parameters\n",
    "n_hidden_1 = 100\n",
    "n_hidden_2 = 100\n",
    "n_input = total_words\n",
    "n_classes = 2\n",
    "\n",
    "input_tensor = tf.placeholder(tf.float32, [None, n_input], name = 'input')\n",
    "output_tensor = tf.placeholder(tf.float32, [None, n_classes], name = 'output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(input_tensor, weights, biases):\n",
    "    layer_1_multiplication = tf.matmul(input_tensor, weights['h1'])\n",
    "    layer_1_addition = tf.add(layer_1_multiplication, biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1_addition)\n",
    "    \n",
    "    #relu activation layer\n",
    "    layer_2_multiplication = tf.matmul(layer_1, weights['h2'])\n",
    "    layer_2_addition = tf.add(layer_2_multiplication, biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2_addition)\n",
    "    \n",
    "    #outpur layer\n",
    "    out_layer_multiplication = tf.matmul(layer_2, weights['out'])\n",
    "    out_layer_addition = out_layer_multiplication + biases['out']\n",
    "    \n",
    "    return out_layer_addition    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "#constract model\n",
    "prediction = multilayer_perceptron(input_tensor, weights, biases)\n",
    "\n",
    "#define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = prediction, labels = output_tensor))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 loss = 142.990193551\n",
      "Epoch:  0002 loss = 8.457810515\n",
      "Epoch:  0003 loss = 1.514389339\n",
      "Epoch:  0004 loss = 0.999445257\n",
      "Epoch:  0005 loss = 0.521440702\n",
      "Epoch:  0006 loss = 0.562979542\n",
      "Epoch:  0007 loss = 0.865961109\n",
      "Epoch:  0008 loss = 0.725709166\n",
      "Epoch:  0009 loss = 0.886099337\n",
      "Epoch:  0010 loss = 0.952546857\n",
      "Optimization finished.\n",
      "Accuracy:  0.9024457\n",
      "Model saved to path: /tmp/model6133.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    #training\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(len(train.output)/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = get_batch(train, i, batch_size)\n",
    "            c, _ = sess.run([loss, optimizer], feed_dict = {input_tensor: batch_x, output_tensor: batch_y})\n",
    "            #compute avg loss\n",
    "            avg_cost += c / total_batch\n",
    "        if epoch%display_step == 0:\n",
    "            print('Epoch: ', '%04d'% (epoch+1), \"loss = \" \\\n",
    "                 \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization finished.\")\n",
    "    \n",
    "    #test model\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(output_tensor, 1))\n",
    "    \n",
    "    #calc accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    total_test_data = len(test.label)\n",
    "    batch_x_test, batch_y_test = get_batch(test, 0, total_test_data)\n",
    "    print('Accuracy: ', accuracy.eval({input_tensor: batch_x_test, output_tensor: batch_y_test}))\n",
    "    \n",
    "    save_path = saver.save(sess, \"/tmp/model6133.ckpt\")\n",
    "    print(\"Model saved to path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 120 range:  119119 - 120119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 121 range:  120120 - 121120\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 122 range:  121121 - 122121\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 123 range:  122122 - 123122\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 124 range:  123123 - 124123\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 125 range:  124124 - 125124\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 126 range:  125125 - 126125\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 127 range:  126126 - 127126\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 128 range:  127127 - 128127\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 129 range:  128128 - 129128\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 130 range:  129129 - 130129\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 131 range:  130130 - 131130\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 132 range:  131131 - 132131\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 133 range:  132132 - 133132\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 134 range:  133133 - 134133\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 135 range:  134134 - 135134\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 136 range:  135135 - 136135\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 137 range:  136136 - 137136\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 138 range:  137137 - 138137\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 139 range:  138138 - 139138\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 140 range:  139139 - 140139\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 141 range:  140140 - 141140\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 142 range:  141141 - 142141\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 143 range:  142142 - 143142\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 144 range:  143143 - 144143\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 145 range:  144144 - 145144\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 146 range:  145145 - 146145\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 147 range:  146146 - 147146\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 148 range:  147147 - 148147\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 149 range:  148148 - 149148\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 150 range:  149149 - 150149\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 151 range:  150150 - 151150\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 152 range:  151151 - 152151\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 153 range:  152152 - 153152\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 154 range:  153153 - 154153\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 155 range:  154154 - 155154\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 156 range:  155155 - 156155\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 157 range:  156156 - 157156\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 158 range:  157157 - 158157\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 159 range:  158158 - 159158\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 160 range:  159159 - 160159\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 161 range:  160160 - 161160\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 162 range:  161161 - 162161\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 163 range:  162162 - 163162\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 164 range:  163163 - 164163\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 165 range:  164164 - 165164\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 166 range:  165165 - 166165\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 167 range:  166166 - 167166\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 168 range:  167167 - 168167\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 169 range:  168168 - 169168\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model6133.ckpt\n",
      "Model restored.\n",
      "Slice # 170 range:  169169 - 170169\n"
     ]
    }
   ],
   "source": [
    "#slice of documents\n",
    "last = 1000\n",
    "\n",
    "#range must start from 1\n",
    "for i in range(1, 171):\n",
    "    \n",
    "    df_run = df_docs._slice(slice(i-1 + (i-1)*last, last*i+i-1), 0)\n",
    "    \n",
    "    x_10_texts, y_10_correct_labels = get_batch(df_run, 0, 1000*i)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"/tmp/model6133.ckpt\")\n",
    "        print(\"Model restored.\")\n",
    "        print('Slice #', i, \"range: \", i-1 + (i-1)*last, \"-\", last*i+i-1)\n",
    "        classification = sess.run(tf.argmax(prediction, 1), feed_dict = {input_tensor: x_10_texts})\n",
    "        df_docs['label'][df_docs._slice(slice(i-1 + (i-1)*last, last*i+i-1), 0).index] = classification\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
